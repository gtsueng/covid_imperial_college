{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "\n",
    "def create_curationObject():\n",
    "    now = datetime.now()\n",
    "    curatedBy = {\n",
    "    \"@type\": \"Organization\",\n",
    "    'identifier': 'imperialcollege',\n",
    "    'url': 'http://www.imperial.ac.uk/mrc-global-infectious-disease-analysis/covid-19/covid-19-reports/',\n",
    "    \"name\": \"MRC Centre for Global Infectious Disease Analysis\",\n",
    "    \"affiliation\": [\"Imperial College London\"],\n",
    "    \"curationDate\":now.strftime(\"%Y-%m-%d\")\n",
    "    }    \n",
    "    return(curatedBy)\n",
    "\n",
    "\n",
    "def get_report_links(reports_url):\n",
    "    recordlist = requests.get(reports_url)\n",
    "    spiralbase = \"https://spiral.imperial.ac.uk:8443/\"\n",
    "    parsedrecordlist = BeautifulSoup(recordlist.text, \"html.parser\")\n",
    "    urlstable = parsedrecordlist.findAll(\"table\")[0]\n",
    "    urlstublist = urlstable.findAll(\"a\")\n",
    "    url_list = []\n",
    "    for eachlink in urlstublist:\n",
    "        tmpurl = spiralbase+eachlink.get(\"href\")\n",
    "        url_list.append(tmpurl)\n",
    "    return(url_list)\n",
    "\n",
    "\n",
    "def get_meta_content(metacontentfield):\n",
    "    if len(metacontentfield) == 1:\n",
    "        metacontentlist = metacontentfield[0].get(\"content\")\n",
    "    else:\n",
    "        metacontentlist = []\n",
    "        for eachitem in metacontentfield:\n",
    "            metaitem = eachitem.get(\"content\")\n",
    "            metacontentlist.append(metaitem)\n",
    "    return(metacontentlist)  \n",
    "\n",
    "\n",
    "def transform_pub_meta(soupobject):\n",
    "    urlfield = soupobject.findAll(\"meta\", {\"name\":\"citation_pdf_url\"})\n",
    "    url = get_meta_content(urlfield)\n",
    "    titlefield = soupobject.findAll(\"meta\", {\"name\":\"citation_title\"})\n",
    "    title = get_meta_content(titlefield)\n",
    "    datePublishedfield = soupobject.findAll(\"meta\", {\"name\":\"citation_date\"})\n",
    "    datePublished = get_meta_content(datePublishedfield)\n",
    "    abstractfield = soupobject.findAll(\"meta\", {\"name\":\"DCTERMS.abstract\"})\n",
    "    abstract = get_meta_content(abstractfield)\n",
    "    defaultidurlfield = soupobject.findAll(\"meta\", {\"scheme\":\"DCTERMS.URI\"})\n",
    "    defaultid = get_meta_content(defaultidurlfield)\n",
    "    tmpdict = {\n",
    "        \"@context\": {\n",
    "        \"schema\": \"http://schema.org/\",\n",
    "        \"outbreak\": \"https://discovery.biothings.io/view/outbreak/\"\n",
    "        },\n",
    "        \"@type\": \"Publication\",\n",
    "        \"journalName\": \"Imperial College London\",\n",
    "        \"journalNameAbbreviation\": \"imperialcollege\",\n",
    "        \"publicationType\": \"Report\", \n",
    "        \"abstract\":abstract,\n",
    "        \"name\":title,\n",
    "        \"datePublished\":datePublished,\n",
    "        \"url\":url,\n",
    "        \"identifier\":defaultid\n",
    "    }\n",
    "    keywordsfield = soupobject.findAll(\"meta\", {\"name\":\"DC.subject\"})\n",
    "    if len(keywordsfield)>0:\n",
    "        keywordsobject = get_meta_content(keywordsfield)\n",
    "        tmpdict[\"keywords\"] = keywordsobject\n",
    "\n",
    "    licensefield = soupobject.findAll(\"meta\", {\"name\":\"DC.rights\"})\n",
    "    if len(licensefield)>0:\n",
    "        license = get_meta_content(licensefield)\n",
    "        tmpdict[\"license\"] = license\n",
    "        \n",
    "    identifiersfield = soupobject.findAll(\"meta\", {\"name\":\"DC.identifier\"})\n",
    "    for eachitem in identifiersfield:\n",
    "        eachitemcontent = eachitem.get(\"content\")\n",
    "        if \"doi\" in eachitemcontent:\n",
    "            doi = eachitemcontent.replace(\"https://doi.org/\",\"\")\n",
    "            tmpdict[\"identifier\"] = \"icl_\"+doi.split('/', 1)[-1]\n",
    "            tmpdict[\"doi\"] = doi\n",
    "        elif \"10.\" in eachitemcontent:\n",
    "            doi = eachitemcontent\n",
    "            tmpdict[\"identifier\"] = \"icl_\"+doi.split('/', 1)[-1]\n",
    "            tmpdict[\"doi\"] = doi\n",
    "    tmpdict['_id'] = tmpdict[\"identifier\"]\n",
    "    return(tmpdict)\n",
    "\n",
    "\n",
    "def get_authors(soupobject):\n",
    "    authorsfield = soupobject.findAll(\"meta\", {\"name\":\"citation_author\"})\n",
    "    authors = get_meta_content(authorsfield)\n",
    "    authorlist = []\n",
    "    for eachauthor in authors:\n",
    "        authparse = eachauthor.split(\",\")\n",
    "        if (len(authparse) == 2) and len(authparse[1])<3:\n",
    "            authdict = {'@type': 'outbreak:Person', 'affiliation': [], 'name': eachauthor, \n",
    "                       'familyName':authparse[0]}\n",
    "        else:\n",
    "            authdict = {'@type': 'outbreak:Person', 'affiliation': [], 'name': eachauthor}\n",
    "        authorlist.append(authdict)\n",
    "    return(authorlist)\n",
    "\n",
    "\n",
    "def get_funding(soupobject):\n",
    "    fundersfield = soupobject.findAll(\"meta\", {\"name\":\"DC.contributor\"})\n",
    "    funders = get_meta_content(fundersfield)\n",
    "    fundercheck = len(fundersfield)\n",
    "    if fundercheck > 0:\n",
    "        identifiersfield = soupobject.findAll(\"meta\", {\"name\":\"DC.identifier\"}) \n",
    "        fundidlist = []\n",
    "        for eachitem in identifiersfield:\n",
    "            eachitemcontent = eachitem.get(\"content\")\n",
    "            if \"https:\" in eachitemcontent:\n",
    "                miscurls = eachitemcontent\n",
    "            else:\n",
    "                fundingid = eachitemcontent\n",
    "                fundidlist.append(fundingid)\n",
    "        fundlist = []\n",
    "        i=0\n",
    "        while i < len(funders):\n",
    "            fundict = {\"@type\": \"MonetaryGrant\",\n",
    "                       \"funder\": {\n",
    "                       \"name\": funders[i]\n",
    "                       },\n",
    "                      \"identifier\": fundidlist[i],\n",
    "            }\n",
    "            fundlist.append(fundict)\n",
    "            i=i+1\n",
    "        fundflag = True\n",
    "    else:\n",
    "        fundlist = []\n",
    "        fundflag = False\n",
    "    return(fundlist, fundflag)\n",
    "\n",
    "\n",
    "def create_id(description_text):\n",
    "    words = description_text.lower().split()\n",
    "    letters = [word[0] for word in words]\n",
    "    identifier = \"icl_\"+\"\".join(e for e in letters if e.isalnum())\n",
    "    return(identifier)\n",
    "\n",
    "\n",
    "def transform_resource_meta(metaobject):\n",
    "    baseurl = \"http://www.imperial.ac.uk\"\n",
    "    tmpdict = {\n",
    "      \"@context\": {\n",
    "        \"schema\": \"http://schema.org/\",\n",
    "        \"outbreak\": \"https://discovery.biothings.io/view/outbreak/\"\n",
    "      },\n",
    "      \"author\": {\n",
    "        \"@type\": \"Organization\",\n",
    "        \"name\": 'Imperial College COVID-19 Response Team',\n",
    "        \"affiliation\": [\"MRC Centre for Global Infectious Disease Analysis\",\n",
    "                        \"Imperial College London\"]\n",
    "      }\n",
    "    }\n",
    "    tmpdict['name'] = metaobject.find(\"h3\",{\"class\":\"title\"}).get_text()\n",
    "    tmpdict['description'] = metaobject.find(\"p\").get_text()\n",
    "    tmpdict['identifier'] = create_id(tmpdict['description'])\n",
    "    tmpdict['_id'] = tmpdict['identifier']\n",
    "    basetype = metaobject.find(\"span\",{\"class\":\"link primary\"}).get_text()\n",
    "    tmpurl = metaobject.find(\"a\").get(\"href\") \n",
    "    \n",
    "    if \"http\" in tmpurl:\n",
    "        url = tmpurl\n",
    "    else:\n",
    "        url = baseurl+tmpurl\n",
    "    try:\n",
    "        basedate = re.findall(\"\\(\\d{2}\\-\\d{2}\\-\\d{4}\\)\", tmpdict['description'])[0].strip(\"(\").strip(\")\")\n",
    "        datetime_object = datetime.strptime(basedate, '%d-%m-%Y')\n",
    "        datePublished = datetime_object.strftime(\"%Y-%m-%d\")\n",
    "    except:\n",
    "        datePublished = \"Not Available\"  \n",
    "    if \"data\" in basetype:\n",
    "        tmpdict['@type'] = \"Dataset\"\n",
    "        tmpdict['distribution'] = {\n",
    "            \"contentUrl\": url,\n",
    "            \"dateModified\": datePublished\n",
    "        }\n",
    "        tmpdict['species']: \"Homo sapiens\"\n",
    "        tmpdict['infectiousAgent']: \"SARS-CoV-2\"\n",
    "    elif \"code\" in basetype:\n",
    "        tmpdict['@type'] = \"SoftwareSourceCode\"\n",
    "        tmpdict['downloadUrl'] = url\n",
    "        tmpdict['datePublished'] = datePublished\n",
    "    elif \"survey\" in basetype:\n",
    "        tmpdict['@type'] = \"Protocol\"\n",
    "        tmpdict['url'] = url\n",
    "        tmpdict['datePublished'] = datePublished\n",
    "        tmpdict['protocolSetting'] = \"public\"\n",
    "        tmpdict[\"protocolCategory\"] = \"protocol\"\n",
    "    if \"for \\\"Report\" in tmpdict['description']:\n",
    "        report_check = tmpdict['description'].replace(\"for \\\"Report\",\"for|Report\").split(\"|\")\n",
    "        citedByTitle = report_check[1].replace('\"','')\n",
    "        tmpdict['citedBy'] = {\"name\": citedByTitle,\n",
    "                              \"type\": \"Publication\"}\n",
    "    return(tmpdict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reports():\n",
    "    reports_url = 'https://spiral.imperial.ac.uk:8443/handle/10044/1/78555/simple-search?location=10044%2F1%2F78555&query=&filter_field_1=type&filter_type_1=equals&filter_value_1=Report&rpp=100&sort_by=score&order=DESC&etal=1&submit_search=Update'\n",
    "    url_list = get_report_links(reports_url)\n",
    "    curatedBy = create_curationObject()\n",
    "\n",
    "    for each_url in url_list[0:5]:\n",
    "        record_result = requests.get(each_url)\n",
    "        parsed_record = BeautifulSoup(record_result.text, \"html.parser\")\n",
    "        base_info = transform_pub_meta(parsed_record)\n",
    "        base_info[\"curatedBy\"] = curatedBy\n",
    "        author_list = get_authors(parsed_record)\n",
    "        fund_list, fund_flag = get_funding(parsed_record)\n",
    "        ## Create the Json\n",
    "        base_info[\"author\"] = author_list\n",
    "        if fund_flag == True:\n",
    "            base_info[\"funding\"] = fund_list\n",
    "        \n",
    "        yield(base_info)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resources():\n",
    "    curatedBy = create_curationObject()\n",
    "    url = 'http://www.imperial.ac.uk/mrc-global-infectious-disease-analysis/covid-19/covid-19-scientific-resources/'\n",
    "    response = requests.get(url)\n",
    "    parsedlisting = BeautifulSoup(response.text, \"html.parser\")\n",
    "    resourceclass = parsedlisting.findAll(\"div\", {\"class\": \"media-item full light-secondary reverse equal-height\"})\n",
    "    resourcelist = []\n",
    "    for eachblock in resourceclass[0:5]:\n",
    "        tmpdict = transform_resource_meta(eachblock)\n",
    "        tmpdict[\"curatedBy\"] = curatedBy\n",
    "        yield(tmpdict)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_analyses():\n",
    "    baseurl = 'http://www.imperial.ac.uk'\n",
    "    curatedBy = create_curationObject()\n",
    "    analysislisturl = 'http://www.imperial.ac.uk/mrc-global-infectious-disease-analysis/covid-19/covid-19-planning-tools/'\n",
    "    analysisresponse = requests.get(analysislisturl)\n",
    "    analysislisting = BeautifulSoup(analysisresponse.text, \"html.parser\")\n",
    "    analysisclass = analysislisting.findAll(\"div\", {\"class\": \"media-item full light-secondary reverse equal-height\"})\n",
    "\n",
    "    for eachblock in analysisclass[0:5]:\n",
    "        tmpdict = {\n",
    "          \"@context\": {\n",
    "            \"schema\": \"http://schema.org/\",\n",
    "            \"outbreak\": \"https://discovery.biothings.io/view/outbreak/\"\n",
    "          },\n",
    "          \"author\": {\n",
    "            \"@type\": \"Organization\",\n",
    "            \"name\": 'Imperial College COVID-19 Response Team',\n",
    "            \"affiliation\": [\"MRC Centre for Global Infectious Disease Analysis\",\n",
    "                            \"Imperial College London\"]\n",
    "          }\n",
    "        }\n",
    "        tmpdict['name'] = eachblock.find(\"h3\",{\"class\":\"title\"}).get_text()\n",
    "        tmpurl = eachblock.find(\"a\").get(\"href\") \n",
    "        tmpdict['species'] = \"Homo sapiens\"\n",
    "        tmpdict['infectiousAgent'] = \"SARS-CoV-2\"\n",
    "        tmpdict['infectiousDisease'] = \"COVID-19\"\n",
    "        tmpdict['description'] = eachblock.find(\"p\").get_text()\n",
    "        tmpdict['identifier'] = create_id(tmpdict['description'])\n",
    "        tmpdict['_id'] = tmpdict['identifier']\n",
    "        tmpdict[\"curatedBy\"] = curatedBy\n",
    "        if \"http\" in tmpurl:\n",
    "            tmpdict['url'] = tmpurl\n",
    "        else:\n",
    "            tmpdict['url'] = baseurl+tmpurl\n",
    "        tmpdict['datePublished'] = 'Not Available'\n",
    "        yield(tmpdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_annotations():\n",
    "    report_list = get_reports()\n",
    "    yield from(report_list)\n",
    "        \n",
    "    resource_list = get_resources()\n",
    "    yield from(resource_list)\n",
    "        \n",
    "    analyses_list = get_analyses()\n",
    "    yield from(analyses_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_anns = load_annotations()\n",
    "for eachann in all_anns:\n",
    "    with open('results/sample.json', 'a') as outwrite:\n",
    "        json.dump(eachann,outwrite)\n",
    "        outwrite.write(\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
